<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><link rel="canonical" href="https://example.enerzai.com/optimav2/guide/install/" />
      <link rel="shortcut icon" href="../../img/favicon.ico" />
    <title>Install - OptimaV2 Document</title>
    <link rel="stylesheet" href="../../css/theme.css" />
    <link rel="stylesheet" href="../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
        <link href="../../template/style.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Install";
        var mkdocs_page_input_path = "guide/install.md";
        var mkdocs_page_url = "/optimav2/guide/install/";
      </script>
    
    <script src="../../js/jquery-3.6.0.min.js" defer></script>
    <!--[if lt IE 9]>
      <script src="../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
      <script>hljs.initHighlightingOnLoad();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../.." class="icon icon-home"> OptimaV2 Document
        </a>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../..">Home</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../about/">About</a>
                </li>
              </ul>
              
                      <p class="caption"><span class="caption-text">User Guide</span></p>
              
              <ul class="current">
                  <li class="toctree-l1 current"><a class="reference internal current" href="./">Install</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#system-requirements">System requirements</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#installing-optimav2">Installing OptimaV2</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#installing-optimav2-runtime">Installing OptimaV2 Runtime</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#troubleshooting">Troubleshooting</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#contact-us">Contact us</a>
    </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../convert/">Convert</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../inference/">Inference</a>
                  </li>
              </ul>
              
                      <p class="caption"><span class="caption-text">Opto Language</span></p>
              
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../kernel/builtin/">Builtin Functions</a>
                  </li>
              </ul>
              
                      <p class="caption"><span class="caption-text">Runtime API Reference</span></p>
              
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../runtime/cpp/">C++</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../runtime/python/">Python</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../..">OptimaV2 Document</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../.." class="icon icon-home" alt="Docs"></a> &raquo;</li>
          <li>User Guide &raquo;</li>
      <li>Install</li>
    <li class="wy-breadcrumbs-aside">
          <a href="https://github.com/ENERZAi/OptimaV2-Docs/edit/master/docs/guide/install.md" class="icon icon-github"> Edit on GitHub</a>
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="installation-guide">Installation guide<a class="headerlink" href="#installation-guide" title="Permanent link">&para;</a></h1>
<p>This document will guide you for installing the OptimaV2 in your systemm and OptimaV2 runtime on your target.</p>
<p>There are 3 components required to compile and run your model with OptimaV2</p>
<ul>
<li>OptimaV2 compiler</li>
<li>OptimaV2 runtime</li>
<li>torch2nx </li>
<li>torch-mlir (To be deprecated)</li>
</ul>
<p>This guide will let you install all requirements for using OptimaV2, Assuming you have host system satisfying <em>System requirements</em> connected to ENERZAi local network, and python 3.10 or above installed with virtual environment tool (venv or anaconda).</p>
<p>Since OptimaV2 is on alpha testing phase, it is not yet open to public network yet. Therefore, you must be connected to ENERZAi local network for installation. We apologize for this inconvenience.</p>
<h3 id="system-requirements">System requirements<a class="headerlink" href="#system-requirements" title="Permanent link">&para;</a></h3>
<div class="tabbed-set tabbed-alternate" data-tabs="1:2"><input checked="checked" id="__tabbed_1_1" name="__tabbed_1" type="radio" /><input id="__tabbed_1_2" name="__tabbed_1" type="radio" /><div class="tabbed-labels"><label for="__tabbed_1_1">OptimaV2 Compiler</label><label for="__tabbed_1_2">OptimaV2 Runtime</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<ul>
<li>CPU : amd64 (Intel64) based processor<ul>
<li>Intel Core i5 6600 (or AMD processor of similar performance) or above is recommended</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>arm64 is supposed to work, but we did not finish our tests on it</p>
</div>
</li>
<li>Operating system : Ubuntu linux 22.04<ul>
<li>Apple macos is also supposed to work, but we did not finish our tests on it</li>
</ul>
</li>
<li>At least 8GB or more ram is recommended</li>
</ul>
</div>
<div class="tabbed-block">
<ul>
<li>CPU : amd64 (Intel64) or arm64 based processor<ul>
<li>Tested on following platforms<ul>
<li>raspberry pi (64bit ubuntu, 64bit raspbian)</li>
<li>Qualcomm SM-8150 develepment board (ubuntu 18.04 LTS)</li>
<li>amd64 based linux systems</li>
</ul>
</li>
</ul>
</li>
<li>Operating system : Linux (ubuntu 18.04 with python 3.6 or above)</li>
</ul>
</div>
</div>
</div>
<h2 id="installing-optimav2">Installing OptimaV2<a class="headerlink" href="#installing-optimav2" title="Permanent link">&para;</a></h2>
<div class="tabbed-set tabbed-alternate" data-tabs="2:3"><input checked="checked" id="__tabbed_2_1" name="__tabbed_2" type="radio" /><input id="__tabbed_2_2" name="__tabbed_2" type="radio" /><input id="__tabbed_2_3" name="__tabbed_2" type="radio" /><div class="tabbed-labels"><label for="__tabbed_2_1">Using Docker</label><label for="__tabbed_2_2">Install using pip</label><label for="__tabbed_2_3">Building from source (Full)</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p>Using docker image is the simplest way for using OptimaV2 However, this is limited for system with amd64 (or x86_64) and CUDA support. </p>
<p>From the enerzai docker registry, you can pull the image with this command</p>
<div class="highlight"><pre><span></span><code>docker<span class="w"> </span>pull<span class="w"> </span>ezcr.enerzai.com/optima-v2:&lt;version&gt;
</code></pre></div>
<p>Now you can run the image using </p>
<div class="highlight"><pre><span></span><code>docker<span class="w"> </span>run<span class="w"> </span>--gpus<span class="w"> </span>all<span class="w"> </span>-it<span class="w"> </span>ezcr.enerzai.com/optima-v2:&lt;version&gt;<span class="w"> </span>/bin/bash
</code></pre></div>
<p>This image has all requirements already installed including OptimaV2 runtime. You can import torch2nx on your code and try out OptimaV2 directly!</p>
</div>
<div class="tabbed-block">
<p>We can also install OptimaV2 components using python pip. We have our dedicated pypi server hosted in Garnet. You can install using pip from it. However, you must be connected to ENERZAi internal network</p>
<p>Installing OptimaV2 via pip is just simple as below</p>
<p><strong>Step 0:</strong> create conda environment to install OptimaV2 (or any virtual enviornment will do)
<div class="highlight"><pre><span></span><code>conda<span class="w"> </span>create<span class="w"> </span>-n<span class="w"> </span>OptimaV2
</code></pre></div>
We recommend you installing OptimaV2 on python virtual environment to prevent version mismatches with your original installation. Moreover, we highly recommend you to not install it with 'sudo', since it will install and might change pre-installed package versions system wide.</p>
<p><strong>Step 1:</strong> Install torch-mlir (This dependency is going to be deprecated will be removed in future releases)
<div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>--index<span class="w"> </span>http://192.168.0.80:12321<span class="w"> </span>--trusted-host<span class="w"> </span><span class="m">192</span>.168.0.80<span class="w">  </span>--no-deps<span class="w"> </span>-f<span class="w"> </span>.<span class="w">  </span>--pre<span class="w"> </span>torch-mlir<span class="o">==</span><span class="m">20221010</span>.622
</code></pre></div></p>
<p><strong>Step 2:</strong> Install torch2nx (zaiConverter)
<div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>--index<span class="w"> </span>http://192.168.0.80:12321<span class="w"> </span>--trusted-host<span class="w"> </span><span class="m">192</span>.168.0.80<span class="w"> </span><span class="nv">zaiConverter</span><span class="o">==</span><span class="m">1</span>.4.2
</code></pre></div>
This process will prompt you to enter github token or username if you don't have access privilege to torch2nx library. In this case, contact OptimaV2 team. We will grant you permissions for installing torch2nx</p>
<p><strong>Step 3</strong> Install OptimaV2 compiler
<div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>--index<span class="w"> </span>http://192.168.0.80:12321<span class="w"> </span>--trusted-host<span class="w"> </span><span class="m">192</span>.168.0.80<span class="w"> </span>optima-v2<span class="o">==</span><span class="m">0</span>.1.0
</code></pre></div></p>
<p>Now, your installation should be complete for OptimaV2 compiler and user interface. You should have no problem compiling your model down to runtime binary. However, We recommend you to install OptimaV2 runtime and verify your OptimaV2 installation before using it. Such steps are described from Step 4.</p>
<p><strong>Step 4:</strong> Install OptimaV2 runtime (Recommended)
<div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>--index<span class="w"> </span>http://192.168.0.80:12321<span class="w"> </span>--trusted-host<span class="w"> </span><span class="m">192</span>.168.0.80<span class="w"> </span>optima-v2-runtime<span class="o">==</span><span class="m">0</span>.1.0
</code></pre></div></p>
<p>This will install OptimaV2 runtime on your system.</p>
<p><strong>Step 5:</strong> Verify your installation (Recommended)
<div class="highlight"><pre><span></span><code>python3<span class="w"> </span>python/tests/test_manager/test.py<span class="w"> </span>&gt;<span class="w"> </span>log.txt
</code></pre></div>
This test internally tests some of our test models. It compiles sample pytorch model down to binary using OptimaV2 and runs it on OptimaV2 runtime. Output from OptimaV2 runtime is verified using output from pytorch.</p>
<p>Detailed test output will be written in log.txt. This will take few minutes to complete. If your terminal shows OK at the end, your installation is complete.</p>
<p>If this outputs 'E' in the terminal, it means there was some problem during your installation. In this case, please send us log.txt file and contact us. We will be greateful to help you out.</p>
</div>
<div class="tabbed-block">
<p>You can build your own version of OptimaV2. 
<strong>Step 0:</strong> Install requirements</p>
<p>We first need to install requrements to build and use OptimaV2. For building OptimaV2 with torch2nx, We need following dependencies. Please note this guide assumes you don't have anything installed in your system. If you already have them installed in your system, you can skip this step.</p>
<ul>
<li>Ubuntu 22.04</li>
<li>python 3.10 or above</li>
<li>Cython</li>
<li>LLVM 15.0.1 (with clang and lld)</li>
<li>MLIR</li>
<li>protocol buffer v21.7 </li>
<li>Optional : anaconda (or venv is possible)</li>
<li>Optional : NVIDIA CUDA (optional)</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Protocol buffer must have been installed with -fPIC (position independent code) option. If your installation does not support it, you will have to re-install it. Please refer to section 'h' for installing protocol buffer in proper way.</p>
</div>
<p>a. First, we need to install llvm from apt-get first for building MLIR. (MLIR would not build if it was built with gcc &amp; g++)</p>
<pre><code>apt-get update &amp;&amp; apt-get install -yq wget &amp;&amp; wget https://apt.llvm.org/llvm-snapshot.gpg.key &amp;&amp;\
apt-key add llvm-snapshot.gpg.key &amp;&amp;\    
apt-get update &amp;&amp;\
apt-get install software-properties-common -yq &amp;&amp;\
apt-add-repository "deb http://apt.llvm.org/jammy/ llvm-toolchain-jammy-15 main" &amp;&amp;\
apt-get update &amp;&amp; apt-get install clang-15 libomp-dev lld -yq
</code></pre>
<p>b. Update alternatives </p>
<pre><code>update-alternatives --install /usr/bin/clang clang /usr/bin/clang-15 1 &amp;&amp;\
update-alternatives --install /usr/bin/clang++ clang++ /usr/bin/clang++-15 1
</code></pre>
<p>c. Install dependencies and python3</p>
<pre><code>apt-get update &amp;&amp; \
apt-get -yq install cmake \
lcov git ninja-build python3 python3-pip \
build-essential checkinstall zlib1g-dev \
libssl-dev wget clang-format &amp;&amp; \
apt-get clean &amp;&amp; \
rm -rf /var/lib/apt/lists/*
</code></pre>
<p>d. Install python package dependencies (You can optionally skip this process, but we recommend using virtual python environment from here  to reduce potential problems caused by version mismatches)</p>
<pre><code>pip3 install numpy==1.23.3 pybind11==2.10.0 lit==15.0.1 networkx==2.8.6 torch==1.13.0 Cython
</code></pre>
<p>e. Now, we clone the LLVM project. We use version 15.0.1</p>
<pre><code>git clone --depth 1 --branch llvmorg-15.0.1 https://github.com/llvm/llvm-project.git
</code></pre>
<p>f. Now, we can build our project using cmake.</p>
<p>This process will install LLVM 15 on your system with MLIR support.</p>
<pre><code># Without CUDA
cmake -S llvm-project/llvm -B llvm-project/build -G Ninja  \
    -DCMAKE_BUILD_TYPE=Release \
    -DPython3_EXECUTABLE:FILEPATH="&lt;path to your python3 executable&gt;" \
    -DMLIR_ENABLE_BINDINGS_PYTHON=ON \
    -DLLVM_ENABLE_PROJECTS="mlir;clang;clang-tools-extra;libc;libclc;lld"\
    -DLLVM_ENABLE_RUNTIMES="libcxx;libcxxabi;libunwind;compiler-rt"\
    -DLLVM_TARGETS_TO_BUILD="AArch64;ARM;X86;Hexagon;RISCV;NVPTX;AMDGPU;WebAssembly"\
    -DLLVM_INSTALL_UTILS=ON\
    -DCMAKE_C_COMPILER=clang\
    -DCMAKE_CXX_COMPILER=clang++\
    -DLLVM_ENABLE_LLD=ON\
    -DMLIR_ENABLE_SPIRV_CPU_RUNNER=ON\
    -DMLIR_ENABLE_VULKAN_RUNNER=ON\
    -DMLIR_INCLUDE_TESTS=ON \
    -DMLIR_INCLUDE_INTEGRATION_TESTS=ON

# With CUDA : If you can use CUDA, you can use this script!
cmake -S llvm-project/llvm -B llvm-project/build -G Ninja  \
    -DCMAKE_BUILD_TYPE=Release \
    -DPython3_EXECUTABLE:FILEPATH="&lt;path to your python3 executable&gt;" \
    -DMLIR_ENABLE_BINDINGS_PYTHON=ON \
    -DLLVM_ENABLE_PROJECTS="mlir;clang;clang-tools-extra;libc;libclc;lld"\
    -DLLVM_ENABLE_RUNTIMES="libcxx;libcxxabi;libunwind;compiler-rt"\
    -DLLVM_TARGETS_TO_BUILD="AArch64;ARM;X86;Hexagon;RISCV;NVPTX;AMDGPU;WebAssembly"\
    -DLLVM_INSTALL_UTILS=ON\
    -DCMAKE_C_COMPILER=clang\
    -DCMAKE_CXX_COMPILER=clang++\
    -DLLVM_ENABLE_LLD=ON\
    -DMLIR_ENABLE_CUDA_RUNNER=ON\
    -DMLIR_ENABLE_SPIRV_CPU_RUNNER=ON\
    -DMLIR_ENABLE_VULKAN_RUNNER=ON\
    -DCMAKE_CUDA_COMPILER="&lt;path to your nvcc compiler&gt;"\
    -DMLIR_INCLUDE_TESTS=ON \
    -DMLIR_INCLUDE_INTEGRATION_TESTS=ON
</code></pre>
<p>g. Now, we build and install MLIR. This process might take several minutes depending on your system. You also need root privilege to install MLIR on your system.</p>
<pre><code>cmake --build llvm-project/build --target all -j"$(nproc)"
sudo cmake --install llvm-project/build &amp;&amp; \
ln -s /app/llvm-project/build/bin/llvm-lit /usr/local/bin/llvm-lit
</code></pre>
<p>h. Install protocol buffer. </p>
<pre><code>git clone --depth 1 --branch v21.7 https://github.com/protocolbuffers/protobuf.git
cd protobuf
git submodule update --init
# protocol buffer must be installed with Position independent code option turned on
cmake -G Ninja -DCMAKE_POSITION_INDEPENDENT_CODE=ON . &amp;&amp; cmake --build . &amp;&amp; sudo cmake --install .
</code></pre>
<p><strong>Step 1</strong>: Download OptimaV2 source code (You will need read privilege to torch2nx)</p>
<div class="highlight"><pre><span></span><code>git<span class="w"> </span>clone<span class="w"> </span>git@github.com:ENERZAi/OptimaV2.git
<span class="nb">cd</span><span class="w"> </span>OptimaV2
git<span class="w"> </span>submodule<span class="w"> </span>update<span class="w"> </span>--init<span class="w"> </span>--remote<span class="w"> </span>--recursive
</code></pre></div>
<p><strong>Step 2</strong>: Install torch2nx(zaiConverter)</p>
<div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>--index<span class="w"> </span>http://192.168.0.80:12321<span class="w"> </span>--trusted-host<span class="w"> </span><span class="m">192</span>.168.0.80<span class="w"> </span><span class="nv">zaiConverter</span><span class="o">==</span><span class="m">1</span>.4.2
</code></pre></div>
<p><strong>Step 3:</strong> Install runtime</p>
<div class="highlight"><pre><span></span><code><span class="c1"># This installs runtime from enerzai private pypi. Therefore, you need to be inside the enerzai internal network</span>
pip<span class="w"> </span>install<span class="w"> </span>--index<span class="w"> </span>http://192.168.0.80:12321<span class="w"> </span>--trusted-host<span class="w"> </span><span class="m">192</span>.168.0.80<span class="w"> </span>optima-v2-runtime<span class="o">==</span><span class="m">0</span>.1.0
</code></pre></div>
<p><strong>Step 4:</strong> build .whl file and install whl file</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Execute from the OptimaV2 project root folder</span>
python3<span class="w"> </span>setup.py<span class="w"> </span>bdist_wheel
pip<span class="w"> </span>install<span class="w"> </span>dist/optima_v2-0.1.0-cp310-cp310-linux_x86_64.whl
</code></pre></div>
<p><strong>Step 5:</strong> Verify your installation</p>
<div class="highlight"><pre><span></span><code><span class="c1"># You can run simple test to verify your installation</span>
<span class="c1"># From the OptimaV2 root directory</span>
python3<span class="w"> </span>python/tests/test_manager/test.py<span class="w"> </span>&gt;<span class="w"> </span>log.txt
</code></pre></div>
<p>If this finishes with OK, it verifies your installation was successful</p>
<h2 id="installing-optimav2-runtime">Installing OptimaV2 Runtime<a class="headerlink" href="#installing-optimav2-runtime" title="Permanent link">&para;</a></h2>
<p>Installing OptimaV2 runtime can be done with single <em>pip install</em> command.
<div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>--index<span class="w"> </span>http://192.168.0.80:12321<span class="w"> </span>--trusted-host<span class="w"> </span><span class="m">192</span>.168.0.80<span class="w"> </span>optima-v2-runtime<span class="o">==</span><span class="m">0</span>.1.0
</code></pre></div></p>
<p>Just make sure you install your OptimaV2 runtime on your target device (The device you will run inference).</p>
</div>
</div>
</div>
<h2 id="troubleshooting">Troubleshooting<a class="headerlink" href="#troubleshooting" title="Permanent link">&para;</a></h2>
<ol>
<li>Building MLIR fails with compiler or linker errors</li>
<li>It turns out compilation with MLIR fails when built with GNU toolchains. We recommend using LLVM toolchain for building MLIR</li>
<li>Torch2nx installation requires github token or password, but I don't have one</li>
<li>Please contact OptimaV2 team. We will grant you permissions for installing torch2nx</li>
</ol>
<h2 id="contact-us">Contact us<a class="headerlink" href="#contact-us" title="Permanent link">&para;</a></h2>
<p>We will be always grateful to help you with using OptimaV2 runtime. 
You can contact one of our team members</p>
<ul>
<li>Jaewoo Kim (김재우) <a href="mailto:jaewoo.kim@enerzai.com">jaewoo.kim@enerzai.com</a></li>
<li>Jaeyoon Yoo (유재윤) <a href="mailto:jaeyoon.yoo@enerzai.com">jaeyoon.yoo@enerzai.com</a></li>
<li>Jinhwan Shin (신진환) <a href="mailto:jinhwan.shin@enerzai.com">jinhwan.shin@enerzai.com</a></li>
<li>Changbeom Kang (강창범) <a href="mailto:changbeom.kang@enerzai.com">changbeom.kang@enerzai.com</a></li>
</ul>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../../about/" class="btn btn-neutral float-left" title="About"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../convert/" class="btn btn-neutral float-right" title="Convert">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/ENERZAi/OptimaV2-Docs" class="fa fa-github" style="color: #fcfcfc"> GitHub</a>
        </span>
    
    
      <span><a href="../../about/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../convert/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script>var base_url = '../..';</script>
    <script src="../../js/theme_extra.js" defer></script>
    <script src="../../js/theme.js" defer></script>
      <script src="../../template/sync-tabs.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
